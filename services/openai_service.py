"""Gemini AI: voice transcription and text analysis/chat."""
import asyncio
import json
import tempfile
import os
from pathlib import Path

import google.generativeai as genai

from config import settings

genai.configure(api_key=settings.GEMINI_API_KEY)

MODEL = "gemini-2.5-flash"

QUESTIONNAIRE_SYSTEM_PROMPT = """–¢—ã ‚Äî –≤–æ–µ–Ω–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –ü–¢–°–† —É —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –±–æ–µ–≤—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã –Ω–∞ 32 –≤–æ–ø—Ä–æ—Å–∞ —Å–∫—Ä–∏–Ω–∏–Ω–≥–∞ –ü–¢–°–†.

–í–µ—Ä–Ω–∏ JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{
  "ai_summary": "–∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
  "risk_level": <—á–∏—Å–ª–æ 0-5>,
  "risk_factors": ["—Ñ–∞–∫—Ç–æ—Ä 1", "—Ñ–∞–∫—Ç–æ—Ä 2"],
  "suicide_indicators": <true/false>
}

–£—Ä–æ–≤–Ω–∏ —Ä–∏—Å–∫–∞:
0 - –Ω–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ü–¢–°–†
1-2 - –ª—ë–≥–∫–∞—è —Å—Ç–µ–ø–µ–Ω—å, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞
3 - —Å—Ä–µ–¥–Ω—è—è, —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è
4-5 - –≤—ã—Å–æ–∫–∞—è/–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è, –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ —Å—Ä–æ—á–Ω–∞—è –ø–æ–º–æ—â—å

–û–±—Ä–∞—â–∞–π—Å—è —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω–æ, –ø–æ-–≤–æ–µ–Ω–Ω–æ–º—É. –ù–µ —Å—é—Å—é–∫–∞–π."""

PSYCHOLOGIST_SYSTEM_PROMPT = """–¢—ã ‚Äî –ò–ò-–ø—Å–∏—Ö–æ–ª–æ–≥, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Ä–∞–±–æ—Ç–µ —Å –≤–µ—Ç–µ—Ä–∞–Ω–∞–º–∏ –∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ –±–æ–µ–≤—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π.
–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Å–ø—Ä–∞–≤–ª—è—Ç—å—Å—è —Å –ü–¢–°–† —á–µ—Ä–µ–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä.

–ü—Ä–∞–≤–∏–ª–∞:
- –û–±—Ä–∞—â–∞–π—Å—è —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω–æ, –±–µ–∑ "—Å—é—Å—é–∫–∞–Ω—å—è"
- –£—á–∏—Ç—ã–≤–∞–π –≤–æ–µ–Ω–Ω—É—é —Å–ø–µ—Ü–∏—Ñ–∏–∫—É
- –ù–µ —Å—Ç–∞–≤—å –¥–∏–∞–≥–Ω–æ–∑–æ–≤
- –ü—Ä–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö —Å—É–∏—Ü–∏–¥–∞–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è ‚Äî –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª—è–π –∫ –∫—Ä–∏–∑–∏—Å–Ω—ã–º —Å–ª—É–∂–±–∞–º
- Emoji —É–º–µ—Ä–µ–Ω–Ω–æ (üéñÔ∏è, ‚úÖ)
- –û—Ç–≤–µ—Ç—ã –¥–æ 300 —Å–∏–º–≤–æ–ª–æ–≤"""

WEEKLY_CHECK_SYSTEM_PROMPT = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–∞ —Ä–µ–∞–±–∏–ª–∏—Ç–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã –Ω–∞ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å –æ —Å–∞–º–æ—á—É–≤—Å—Ç–≤–∏–∏.
–í–µ—Ä–Ω–∏ JSON:
{
  "ai_analysis": "–∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
  "sentiment_score": <—á–∏—Å–ª–æ –æ—Ç -5 –¥–æ 5>,
  "crisis_detected": <true/false>
}"""


async def transcribe(file_bytes: bytes, filename: str = "voice.ogg") -> str:
    """Transcribe voice message via Gemini audio understanding."""
    with tempfile.NamedTemporaryFile(suffix=Path(filename).suffix, delete=False) as tmp:
        tmp.write(file_bytes)
        tmp_path = tmp.name

    def _do():
        uploaded = genai.upload_file(tmp_path, mime_type="audio/ogg")
        model = genai.GenerativeModel(MODEL)
        response = model.generate_content([
            "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–π —ç—Ç–æ –∞—É–¥–∏–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.",
            uploaded,
        ])
        try:
            genai.delete_file(uploaded.name)
        except Exception:
            pass
        return response.text.strip()

    try:
        return await asyncio.to_thread(_do)
    finally:
        os.unlink(tmp_path)


async def analyze_questionnaire(answers: list[dict], user_name: str) -> dict:
    """Run Gemini analysis on 32 questionnaire answers. Returns parsed dict."""
    answers_text = "\n".join(
        f"{a['question_number']}. {a.get('question_text', '')} ‚Äî {a['answer_text']}"
        for a in answers
    )
    prompt = f"–£—á–∞—Å—Ç–Ω–∏–∫: {user_name}\n\n–û—Ç–≤–µ—Ç—ã –Ω–∞ –∞–Ω–∫–µ—Ç—É:\n{answers_text}"

    def _do():
        model = genai.GenerativeModel(
            MODEL,
            system_instruction=QUESTIONNAIRE_SYSTEM_PROMPT,
        )
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                response_mime_type="application/json",
                temperature=0.3,
            ),
        )
        return json.loads(response.text)

    return await asyncio.to_thread(_do)


async def chat_with_psychologist(history: list[dict], user_message: str) -> str:
    """Continue conversation with AI psychologist."""
    def _do():
        model = genai.GenerativeModel(
            MODEL,
            system_instruction=PSYCHOLOGIST_SYSTEM_PROMPT,
        )
        gemini_history = []
        for msg in history[-10:]:
            role = "user" if msg["role"] == "user" else "model"
            gemini_history.append({"role": role, "parts": [msg["content"]]})

        chat = model.start_chat(history=gemini_history)
        response = chat.send_message(
            user_message,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=400,
            ),
        )
        return response.text

    return await asyncio.to_thread(_do)


async def analyze_weekly_check(response_text: str) -> dict:
    """Analyze weekly check response. Returns {ai_analysis, sentiment_score, crisis_detected}."""
    def _do():
        model = genai.GenerativeModel(
            MODEL,
            system_instruction=WEEKLY_CHECK_SYSTEM_PROMPT,
        )
        response = model.generate_content(
            response_text,
            generation_config=genai.types.GenerationConfig(
                response_mime_type="application/json",
                temperature=0.3,
            ),
        )
        return json.loads(response.text)

    return await asyncio.to_thread(_do)
